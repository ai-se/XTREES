@article{aha91,
  title={Instance-based learning algorithms},
  author={Aha, David W and Kibler, Dennis and Albert, Marc K},
  journal={Machine learning},
  volume={6},
  number={1},
  pages={37--66},
  year={1991},
  publisher={Springer}
}

@mastersthesis{div14,
  title="Exploring Essential content of Defect Prediction 
         and Effort Estimation through Data Reduction",
  year=2014,
  author="Divya Ganesan",
  school="Computer Science, West Virginia University"
 }
 

@article{kocaguneli2014transfer,
  title={Transfer learning in effort estimation},
  author={Kocaguneli, Ekrem and Menzies, Tim and Mendes, Emilia},
  journal={Empirical Software Engineering},
  pages={1--31},
  year={2014},
  publisher={Springer US}
}

@book{quinlan92,
  title =	 "C4.5: Programs for Machine Learning",
  author =	 "R. Quinlan",
  year =	 1992,
  publisher =	 "Morgan Kaufman",
  note =	 "ISBN: 1558602380"
}
@book{breiman84,
  author =	 "L. Breiman and J. H. Friedman and R. A. Olshen and
                  C. J. Stone",
  title =	 "Classification and Regression Trees",
  institution =	 "Wadsworth International, Monterey, CA",
  year =	 1984,
  annote =	 "cart algorithm"
}
@inproceedings{menzies12a,
  author="T. Menzies and T. Zimmermann",
  title="Goldfish Bowl Panel: Software Development Analytics",
  booktitle="ICSE'12",
  pages="1032-1033"
}

@incollection{rob14,
  author    = {Martin P. Robillard and
               Robert J. Walker},
  title     = {An Introduction to Recommendation Systems in Software Engineering},
  booktitle = {Recommendation Systems in Software Engineering},
  pages     = {1--11},
  year      = {2014},
  crossref  = {DBLP:books/sp/rsse2014},
  url       = {http://dx.doi.org/10.1007/978-3-642-45135-5_1},
  doi       = {10.1007/978-3-642-45135-5_1},
  timestamp = {Mon, 08 Sep 2014 14:46:00 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/books/sp/rsse14/RobillardW14},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}
@book{DBLP:books/sp/rsse2014,
  editor    = {Martin P. Robillard and
               Walid Maalej and
               Robert J. Walker and
               Thomas Zimmermann},
  title     = {Recommendation Systems in Software Engineering},
  booktitle = {Recommendation Systems in Software Engineering},
  publisher = {Springer},
  year      = {2014},
  url       = {http://dx.doi.org/10.1007/978-3-642-45135-5},
  doi       = {10.1007/978-3-642-45135-5},
  isbn      = {978-3-642-45134-8},
  timestamp = {Mon, 08 Sep 2014 14:46:00 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/books/sp/rsse2014},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}



@article{me11f,
  title =	 "Learning Better Inspection Optimization Policies",
  author =	 "M. Lumpe and R. Vasa and T. Menzies and R. Rush and
                  R. Turhan",
  class =	 "hJ",
  volume =	 21,
  number =	 45,
  pages =	 "725-753",
  year =	 2011,
  class =	 "hJ",
  journal =	 "International Journal of Software Engineering and
                  Knowledge Engineering"
}



@inproceedings{zhang14,
 author = {Zhang, Feng and Mockus, Audris and Keivanloo, Iman and Zou, Ying},
 title = {Towards Building a Universal Defect Prediction Model},
 booktitle = {Proceedings of the 11th Working Conference on Mining Software Repositories},
 series = {MSR 2014},
 year = {2014},
 isbn = {978-1-4503-2863-0},
 location = {Hyderabad, India},
 pages = {182--191},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2597073.2597078},
 doi = {10.1145/2597073.2597078},
 acmid = {2597078},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Universal defect prediction model, bug, context factors, defect, defect prediction, large scale, quality, rank transformation},
} 




@ARTICLE{Mendes2007,
  author =	 {Kitchenham, Barbara and Mendes, Emilia and
                  Travassos, Guilherme H.},
  title =	 {Cross versus Within-Company Cost Estimation Studies:
                  A Systematic Review},
  journal =	 {IEEE Trans. Softw. Eng.},
  year =	 2007,
  volume =	 33,
  pages =	 {316--329},
  number =	 5,
  note =	 {Member-Kitchenham, Barbara A.},
  address =	 {Piscataway, NJ, USA},
  doi =		 {http://dx.doi.org/10.1109/TSE.2007.1001},
  issn =	 {0098-5589},
  publisher =	 {IEEE Press}
}


@inproceedings{zimmermann09,
  author =	 "T. Zimmermann and N.  Nagappan and H.  Gall and E.
                  Giger and B.  Murphy",
  title =	 "Cross-Project Defect Prediction",
  booktitle =	 "ESEC/FSE'09",
  month =	 "August",
  year =	 2009
}


@inproceedings{peters15,
  title="LACE2: Better Privacy-Preserving 
         Data Sharing for Cross Project Defect Prediction",
  author="Fayola Peters, Tim Menzies, Lucas Layman"
  booktitle="ICSE'15",
  year=2015
}

@inproceedings{nam13,
 author = {Nam, Jaechang and Pan, Sinno Jialin and Kim, Sunghun},
 title = {Transfer Defect Learning},
 booktitle = {Proceedings of the 2013 International Conference on Software Engineering},
 series = {ICSE '13},
 year = {2013},
 isbn = {978-1-4673-3076-3},
 location = {San Francisco, CA, USA},
 pages = {382--391},
 numpages = {10},
 url = {http://dl.acm.org/citation.cfm?id=2486788.2486839},
 acmid = {2486839},
 publisher = {IEEE Press},
 address = {Piscataway, NJ, USA},
} 


@inproceedings{he13,
  author    = {Zhimin He and
               Fayola Peters and
               Tim Menzies and
               Ye Yang},
  title     = {Learning from Open-Source Projects: An Empirical Study on Defect Prediction},
  booktitle = {2013 {ACM} / {IEEE} International Symposium on Empirical Software
               Engineering and Measurement, Baltimore, Maryland, USA, October 10-11,
               2013},
  pages     = {45--54},
  year      = {2013},
  crossref  = {DBLP:conf/esem/2013},
  url       = {http://dx.doi.org/10.1109/ESEM.2013.20},
  doi       = {10.1109/ESEM.2013.20},
  timestamp = {Mon, 04 Aug 2014 17:08:35 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/esem/HePMY13},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}
@article{Pedregosa2012,
abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.},
archivePrefix = {arXiv},
arxivId = {1201.0490},
author = {Pedregosa, Fabian and Varoquaux, Ga\"{e}l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot, Matthieu and Duchesnay, \'{E}douard},
eprint = {1201.0490},
file = {::},
isbn = {1532-4435},
issn = {15324435},
journal = { Journal Machine Learning },
pages = {2825--2830},
title = {{Scikit-learn: Machine Learning in Python}},
url = {http://dl.acm.org/citation.cfm?id=2078195$\backslash$nhttp://arxiv.org/abs/1201.0490},
volume = {12},
year = {2012}
}


@article{Anda2009,
abstract = {The scientific study of a phenomenon requires it to be reproducible. Mature engineering industries are recognized by projects and products that are, to some extent, reproducible. Yet, reproducibility in software engineering (SE) has not been investigated thoroughly, despite the fact that lack of reproducibility has both practical and scientific consequences. We report a longitudinal multiple-case study of variations and reproducibility in software development, from bidding to deployment, on the basis of the same requirement specification. In a call for tender to 81 companies, 35 responded. Four of them developed the system independently. The firm price, planned schedule, and planned development process, had, respectively, ldquolow,rdquo ldquolow,rdquo and ldquomediumrdquo reproducibilities. The contractor's costs, actual lead time, and schedule overrun of the projects had, respectively, ldquomedium,rdquo ldquohigh,rdquo and ldquolowrdquo reproducibilities. The quality dimensions of the delivered products, reliability, usability, and maintainability had, respectively, ldquolow,rdquo "high,rdquo and ldquolowrdquo reproducibilities. Moreover, variability for predictable reasons is also included in the notion of reproducibility. We found that the observed outcome of the four development projects matched our expectations, which were formulated partially on the basis of SE folklore. Nevertheless, achieving more reproducibility in SE remains a great challenge for SE research, education, and industry.},
author = {Anda, Bente C D and Sj\o berg, Dag I K and Mockus, Audris},
doi = {10.1109/TSE.2008.89},
isbn = {0098-5589},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Multiple-case study,Software engineering life cycle,Software process,Software project success,Software quality},
number = {3},
pages = {407--429},
title = {{Variability and reproducibility in software engineering: A study of four companies that developed the same system}},
volume = {35},
year = {2009}
}


@article{Mkaouer15,
author = {{Wiem Mkaouer, Marouane Kessentini,; Slim Bechikh, Kalyanmoy Deb}, Ali Ouni and \'{U}\^{u}, \'{O}},
journal = {ACM Trans. Softw. Eng. Methodol.},
title = {{Many-Objective Software Remodularization using NSGA-III}},
volume = {to appear},
year = {2015}
}

@inproceedings{Binkley2006,
abstract = {Aspect-oriented programming (AOP) provides mechanisms for the separation of crosscutting concerns - functionalities scattered through the system and tangled with the base code. Existing systems are a natural testbed for the AOP approach since they often contain several crosscutting concerns which could not be modularized using traditional programming constructs. This paper presents an automated approach to the problem of migrating systems developed according to the object-oriented programming (OOP) paradigm into aspect-oriented programming (AOP). A simple set of six refactorings has been defined to transform OOP to AOP and has been implemented in the AOP-migrator tool, an Eclipse plug-in. A set of enabling transformations from OOP to OOP complement the initial set of refactorings. The paper presents the results of four case studies, which use the approach to migrate selected crosscutting concerns from medium-sized Java programs (in the range of 10K to 40K lines of code) into equivalent programs in AspectJ. The case study results show the feasibility of the migration and indicate the importance of the enabling transformations as a preprocessing step},
author = {Binkley, David and Ceccato, Mariano and Harman, Mark and Ricca, Filippo and Tonella, Paolo},
booktitle = {IEEE Transactions on Software Engineering},
doi = {10.1109/TSE.2006.95},
issn = {00985589},
keywords = {Aspect-oriented software development,Program transformation,Refactoring},
number = {9},
pages = {698--717},
title = {{Tool-supported refactoring of existing object-oriented code into aspects}},
volume = {32},
year = {2006}
}


@inproceedings{fea02a,
author = {Feather, M S and Menzies, T},
booktitle = {IEEE Joint Conference On Requirements Engineering ICRE'02 and RE'02, 9-13th September, University of Essen, Germany},
title = {{Converging on the Optimal Attainment of Requirements}},
year = {2002}
}

@article{Menzies2013:local,
abstract = {Existing research is unclear on how to generate lessons learned for defect prediction and effort estimation. Should we seek lessons that are global to multiple projects or just local to particular projects? This paper aims to comparatively evaluate local versus global lessons learned for effort estimation and defect prediction. We applied automated clustering tools to effort and defect datasets from the PROMISE repository. Rule learners generated lessons learned from all the data, from local projects, or just from each cluster. The results indicate that the lessons learned after combining small parts of different data sources (i.e., the clusters) were superior to either generalizations formed over all the data or local lessons formed from particular projects. We conclude that when researchers attempt to draw lessons from some historical data source, they should 1) ignore any existing local divisions into multiple sources, 2) cluster across all available data, then 3) restrict the learning of lessons to the clusters from other sources that are nearest to the test data.},
author = {Menzies, Tim and Butcher, Andrew and Cok, David and Marcus, Andrian and Layman, Lucas and Shull, Forrest and Turhan, Burak and Zimmermann, Thomas},
doi = {10.1109/TSE.2012.83},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Data mining,clustering,defect prediction,effort estimation},
number = {6},
pages = {822--834},
title = {{Local versus global lessons for defect prediction and effort estimation}},
volume = {39},
year = {2013}
}

@ARTICLE{menzies13:brady, 
author={Menzies, T. and Brady, A. and Keung, J. and Hihn, J. and Williams, S. and El-Rawas, O. and Green, P. and Boehm, B.}, 
journal={Software Engineering, IEEE Transactions on}, 
title={Learning Project Management Decisions: A Case Study with Case-Based Reasoning versus Data Farming}, 
year={2013}, 
month={Dec}, 
volume={39}, 
number={12}, 
pages={1698-1713}, 
keywords={Monte Carlo methods;case-based reasoning;data handling;learning (artificial intelligence);project management;sampling methods;software management;CBR;Monte Carlo sampling;SEESAW;case-based reasoning;data farming;project management decision learning;software project data;Data models;Mathematical model;Monte Carlo methods;Project management;Search methods;Software engineering;COCOMO;Search-based software engineering;case-based reasoning;data farming}, 
doi={10.1109/TSE.2013.43}, 
ISSN={0098-5589},}


@inproceedings{me07f,
abstract = {Adoption of advanced automated SE (ASE) tools would be favored if a business case could be made that these tools are more valuable than alternate methods. In theory, software prediction models can be used to make that case. In practice, this is complicated by the "local tuning" problem. Normally, predictors for software effort and defects and threat use local data to tune their predictions. Such local tuning data is often unavailable. This paper shows that assessing the relative merits of different SE methods need not require precise local tunings. STAR1 is a simulated annealer plus a Bayesian post-processor that explores the space of possible local tunings within software prediction models. STAR1 ranks project decisions by their effects on effort and defects and threats. In experiments with two NASA systems, STAR1 found that ASE tools were necessary to minimize effort/ defect/ threats.},
address = {New York, NY, USA},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/07casease-v0.pdf\}},
author = {Menzies, Tim and Feather, Martin S and Madachy, Ray and Boehm, Barry W.},
booktitle = {Proc. ASE},
doi = {http://doi.acm.org/10.1145/1321631.1321676},
isbn = {978-1-59593-882-4},
pages = {303--312},
publisher = {ACM},
title = {{The Business Case for Automated Software Engineering}},
url = {http://portal.acm.org/citation.cfm?id=1321631.1321676},
year = {2007}
}



@incollection{peng09:ls,
year={2009},
isbn={978-3-540-88050-9},
booktitle={Multi-Objective Memetic Algorithms},
volume={171},
series={Studies in Computational Intelligence},
editor={Goh, Chi-Keong and Ong, Yew-Soon and Tan, KayChen}, 
title={Comparison between MOEA/D and NSGA-II on the Multi-Objective Travelling Salesman Problem},
url={http://dx.doi.org/10.1007/978-3-540-88051-6_14},
publisher={Springer Berlin Heidelberg},
author={Peng, Wei and Zhang, Qingfu and Li, Hui},
pages={309-324},
language={English}
}


@article{igel07,
 author = {Igel, Christian and Hansen, Nikolaus and Roth, Stefan},
 title = {Covariance Matrix Adaptation for Multi-objective Optimization},
 journal = {Evol. Comput.},
 issue_date = {Spring 2007},
 volume = {15},
 number = {1},
 month = mar,
 year = {2007},
 issn = {1063-6560},
 pages = {1--28},
 numpages = {28}, 
 acmid = {1245373},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
 keywords = {Multi-objective optimization, covariance matrix adaptation, evolution strategy},
} 


@inproceedings{kautz97,
  author =	 "H. Kautz and B. Selman and Y. Jiang",
  year =	 1997,
  title =	 "A general stochastic approach to solving problems
                  with hard and soft constraints",
  editor =	 "D. Gu and J. Du and P. Pardalos",
  booktitle =	 "The Satisfiability Problem: Theory and Applications,
                  New York, NY",
  pages =	 " 573--586",
  note =	 "Available on-line at
                  \url{http://citeseer.ist.psu.edu/168907.html}"
}

@article{Selman1992,
abstract = {We introduce a greedy local search procedure called GSAT for solving propositional satisfiability problems. Our experiments show that this procedure can be used to solve hard, randomly generated problems that are an order of magnitude larger than those that can be handled by more traditional approaches such as the Davis-Putnam procedure or resolution. We also show that GSAT can solve structured satisfiability problems quickly. In particular, we solve encodings of graph coloring problems, N-queens, and Boolean induction. General application strategies and limitations of the approach are also discussed. GSAT is best viewed as a model-finding procedure. Its good performance suggests that it may be advantageous to reformulate reasoning tasks that have traditionally been viewed as theorem-proving problems as model-finding tasks.},
author = {Selman, Bart and Levesque, Hector and Mitchell, David},
isbn = {0-262-51063-4},
issn = {08828121},
journal = {Proceedings of the Tenth National Conference on Artificial Intelligence (AAAI'92)},
pages = {440--446},
title = {{A New Method for Solving Hard Satisfiability Problems}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.34.6853\&amp;rep=rep1\&amp;type=pdf},
volume = {20},
year = {1992}
}


@inproceedings{levina04,
author = {Levina, Elizaveta and Bickel, Peter J},
booktitle = {NIPS},
file = {:Users/timm/svns/doc/04intrinsicDimension.pdf:pdf},
title = {{Maximum Likelihood Estimation of Intrinsic Dimension.}},
year = {2004}
}
@article{deb00a,
author = {Deb, Kalyanmoy and Pratap, Amrit and Agarwal, Sameer and Meyarivan, T},
journal = {IEEE Transactions on Evolutionary Computation},
pages = {182--197},
title = {{A Fast Elitist Multi-Objective Genetic Algorithm: NSGA-II}},
volume = {6},
year = {2002}
}

@article{Khuller1995,
abstract = {We present a linear time randomized sieve algorithm for the closest-pair problem. The algorithm and its analysis are simple. The algorithm is extended to obtain a randomized linear time approximation algorithm for the closest bichromatic pair problem.},
author = {Khuller, S and Matias, Y},
doi = {10.1006/inco.1995.1049},
issn = {08905401},
journal = {Information and Computation},
number = {1},
pages = {34--37},
title = {{A Simple Randomized Sieve Algorithm for the Closest-Pair Problem}},
url = {http://www.sciencedirect.com/science/article/pii/S0890540185710498},
volume = {118},
year = {1995}
}


@article{Shamos1975,
abstract = {A number of seemingly unrelated problems involving the proximity of N points in the plane are studied, such as finding a Euclidean minimum spanning tree, the smallest circle enclosing the set, k nearest and farthest neighbors, the two closest points, and a proper straight-line triangulation. For most of the problems considered a lower bound of O(N log N) is shown. For all of them the best currently-known upper bound is O(N2) or worse. The purpose of this paper is to introduce a single geometric structure, called the Voronoi diagram, which can be constructed rapidly and contains all of the relevant proximity information in only linear space. The Voronoi diagram is used to obtain O(N log N) algorithms for all of the problems.},
author = {Shamos, Michael Ian and Hoey, Dan},
doi = {10.1109/SFCS.1975.8},
isbn = {0272-5428},
issn = {0272-5428},
journal = {16th Annual Symposium on Foundations of Computer Science (sfcs 1975)},
title = {{Closest-point problems}},
year = {1975}
}


@inproceedings{me09j,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09pom2.pdf\}},
author = {Lemon, B and Riesbeck, A and Menzies, T and Price, J and D'Alessandro, J and Carlsson, R and Prifiti, T and Peters, F and Lu, H and Port, D},
booktitle = {IEEE ASE'09},
title = {{Applications of Simulation and AI Search: Assessing the Relative Merits of Agile vs Traditional Software Development}},
year = {2009}
}

@article{Chawla2002,
abstract = {An approach to the construction of classifiers from imbalanced datasets is described. A dataset is imbalanced if the classification categories are not approximately equally represented. Often real-world data sets are predominately composed of "normal" examples with only a small percentage of "abnormal" or "interesting" examples. It is also the case that the cost of misclassifying an abnormal (interesting) example as a normal example is often much higher than the cost of the reverse error. Under-sampling of the majority (normal) class has been proposed as a good means of increasing the sensitivity of a classifier to the minority class. This paper shows that a combination of our method of over-sampling the minority (abnormal) class and under-sampling the majority (normal) class can achieve better classifier performance (in ROC space) than only under-sampling the majority class. This paper also shows that a combination of our method of over-sampling the minority class and under-sampling the majority class can achieve better classifier performance (in ROC space) than varying the loss ratios in Ripper or class priors in Naive Bayes. Our method of over-sampling the minority class involves creating synthetic minority class examples. Experiments are performed using C4.5, Ripper and a Naive Bayes classifier. The method is evaluated using the area under the Receiver Operating Characteristic curve (AUC) and the ROC convex hull strategy.},
archivePrefix = {arXiv},
arxivId = {1106.1813},
author = {Chawla, Nitesh V. and Bowyer, Kevin W. and Hall, Lawrence O. and Kegelmeyer, W. Philip},
doi = {10.1613/jair.953},
eprint = {1106.1813},
isbn = {013805326X},
issn = {10769757},
journal = {Journal of Artificial Intelligence Research},
pages = {321--357},
pmid = {18190633},
title = {{SMOTE: Synthetic minority over-sampling technique}},
volume = {16},
year = {2002}
}


@article{Cui2005a,
author = {Cui, X and Potok, Te and Palathingal, P},
file = {:Users/timm/svns/doc/pso/05clusterPSO.pdf:pdf},
journal = {\ldots  Intelligence Symposium, 2005. \ldots},
title = {{Document clustering using particle swarm optimization}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1501621},
year = {2005}
}


@inproceedings{me09i,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09value.pdf\}},
author = {Green, P and Menzies, T and Williams, S and El-waras, O},
booktitle = {IEEE ASE'09},
title = {{Understanding the Value of Software Engineering Technologies}},
year = {2009}
}

@article{storn97,
author = {Storn, Rainer and Price, Kenneth},
doi = {10.1023/A:1008202821328},
file = {:Users/timm/svns/doc/97stornPriceDE.pdf:pdf},
issn = {0925-5001},
journal = {Journal of Global Optimization},
number = {4},
pages = {341--359},
publisher = {Kluwer Academic Publishers},
title = {{Differential Evolution – A Simple and Efficient Heuristic for global Optimization over Continuous Spaces}},
volume = {11},
year = {1997}
}




@incollection{zit04,
author = {Zitzler, Eckart and K\"{u}nzli, Simon},
booktitle = {Parallel Problem Solving from Nature - PPSN VIII},
doi = {10.1007/978-3-540-30217-9\_84},
editor = {Yao, Xin and Burke, EdmundK. and Lozano, Jos\'{e}A. and Smith, Jim and Merelo-Guerv\'{o}s, JuanJuli\'{a}n and Bullinaria, JohnA. and Rowe, JonathanE. and Tiňo, Peter and Kab\'{a}n, Ata and Schwefel, Hans-Paul},
file = {:Users/timm/svns/doc/04zitzlerIBEA.pdf:pdf},
isbn = {978-3-540-23092-2},
pages = {832--842},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Indicator-Based Selection in Multiobjective Search}},
url = {http://dx.doi.org/10.1007/978-3-540-30217-9\_84},
volume = {3242},
year = {2004}
}

@inproceedings{zit02,
author = {Zitzler, Eckart and Laumanns, Marco and Thiele, Lothar},
booktitle = {Evolutionary Methods for Design, Optimisation, and Control},
pages = {95--100},
publisher = {CIMNE, Barcelona, Spain},
title = {{SPEA2: Improving the Strength Pareto Evolutionary Algorithm for Multiobjective Optimization}},
year = {2002}
}

@article{boley98,
author = {Boley, Daniel},
file = {:Users/timm/svns/doc/98principalDirectionDivisvePartitioning.pdf:pdf},
journal = {Data Min. Knowl. Discov.},
month = dec,
number = {4},
pages = {325--344},
title = {{Principal Direction Divisive Partitioning}},
volume = {2},
year = {1998}
}

@mastersthesis{divya15,
  author= "Divya Ganesan",
  title=  "Exploring Essential content of Defect Prediction 
           and Effort Estimation
           through Data Reduction",
  school= "Lane Department of Computer Science and 
           Electrical Engineering, West Virginia University",
  year=    2015
}

@mastersthesis{papa13,
  author="Vasil Papakroni",
  title="Data Carving: Identifying and Removing Irrelevancies in the Data",
  school="Lane Department of Computer Science and Electrical Engineering, West Virginia Unviersity",
  year=2013
}
@article{deb14,
author = {Deb, K and Jain, H},
doi = {10.1109/TEVC.2013.2281535},
file = {:Users/timm/svns/doc/13nsga-III.pdf:pdf},
issn = {1089-778X},
journal = {Evolutionary Computation, IEEE Transactions on},
keywords = {genetic algorithms;sorting;EMO algorithms;MOEA/D m},
month = aug,
number = {4},
pages = {577--601},
title = {{An Evolutionary Many-Objective Optimization Algorithm Using Reference-Point-Based Nondominated Sorting Approach, Part I: Solving Problems With Box Constraints}},
volume = {18},
year = {2014}
}

@article{zhang07:TEC,
author = {Zhang, Qingfu and Li, Hui},
doi = {10.1109/TEVC.2007.892759},
issn = {1089-778X},
journal = {Evolutionary Computation, IEEE Transactions on},
keywords = {computational complexity;genetic algorithms;comput},
month = dec,
number = {6},
pages = {712--731},
title = {{MOEA/D: A Multiobjective Evolutionary Algorithm Based on Decomposition}},
volume = {11},
year = {2007}
}


@inproceedings{me12c,
annote = {Available from http://menzies.us/pdf/12idea.pdf},
author = {Borges, R and Menzies, T},
booktitle = {Proceedings of PROMISE'12, Lund, Sweden},
title = {{Learning to Change Projects}},
year = {2012}
}



@inproceedings{me02f,
author = {Menzies, Tim and Raffo, David and Setamanit, Siri-on and Hu, Ying and Tootoonian, Sina},
booktitle = {Proceedings of IEEE ASE 2002},
title = {{Model-based Tests of Truisms}},
year = {2002}
}

@inproceedings{me00e,
author = {Menzies, T and Sinsel, E},
booktitle = {Proceedings ASE 2000},
title = {{Practical Large Scale What-if Queries: Case Studies with Software Risk Assessment}},
year = {2000}
}


@misc{Fikes1971,
abstract = {We describe a new problem solver called STRIPS that attempts to find a sequence of operators in a space of world models to transform a given initial world model in which a given goal formula can be proven to be true. STRIPS represents a world model as an arbitrary collection in first-order predicate calculus formulas and is designed to work with models consisting of large numbers of formula. It employs a resolution theorem prover to answer questions of particular models and uses means-ends analysis to guide it to the desired goal-satisfying model.},
author = {Fikes, Richard E. and Nilsson, Nils J.},
booktitle = {Artificial Intelligence},
doi = {10.1016/0004-3702(71)90010-5},
isbn = {0004-3702},
issn = {00043702},
number = {3-4},
pages = {189--208},
title = {{Strips: A new approach to the application of theorem proving to problem solving}},
volume = {2},
year = {1971}
}


@inproceedings{zuluaga13,
author = {Zuluaga, Marcela and Krause, Andreas and Sergent, Guillaume and P\"{u}schel, Markus},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Active Learning for Multi-Objective Optimization}},
year = {2013}
}

@article{pearson1901,
author = {Pearson, K},
journal = {Philosophical Magazine},
pages = {559--572},
title = {{On lines and planes of closest fit to systems of points in space}},
volume = {2},
year = {1901}
}



@inproceedings{kamvar03,
author = {Kamvar, Sepandar and Klein, Dan and Manning, Christopher},
booktitle = {IJCAI'03},
pages = {561--566},
title = {{Spectral learning}},
year = {2003}
}

@proceedings{DBLP:conf/esem/2013,
  title     = {2013 {ACM} / {IEEE} International Symposium on Empirical Software
               Engineering and Measurement, Baltimore, Maryland, USA, October 10-11,
               2013},
  publisher = {{IEEE} Computer Society},
  year      = {2013},
  url       = {http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=6681322},
  isbn      = {978-0-7695-5056-5},
  timestamp = {Mon, 04 Aug 2014 17:08:35 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/esem/2013},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@book{boehm00b,
author = {Boehm, Barry and Horowitz, Ellis and Madachy, Ray and Reifer, Donald and Clark, Bradford K and Steece, Bert and Brown, A Winsor and Chulani, Sunita and Abts, Chris},
publisher = {Prentice Hall},
title = {{Software Cost Estimation with Cocomo II}},
year = {2000}
}

@book{boehm81,
author = {Boehm, B},
publisher = {Prentice Hall},
title = {{Software Engineering Economics}},
year = {1981}
}

 
 
 @inproceedings{madachy94,
author = {Madachy, R},
booktitle = {Proceedings Ninth Knowledge-Based Software Engineering Conference},
pages = {172--178},
title = {{Knowledge-based risk assessment and cost estimation}},
year = {1994}
}

 
 @inproceedings{me00e,
abstract = {When a lack of data inhibits decision-making, large-scale what-if
queries can be conducted over the uncertain parameter ranges. Such
queries can generate an overwhelming amount of data. We describe a
general method for understanding that data. Large-scale what-if queries
can guide Monte Carlo simulations of a model. Machine learning can then
be used to summarize the output. The summarization is an ensemble of
decision trees. The TARZAN system [so-called because it swings through
(or searches) the decision trees] can poll the ensemble looking for
majority conclusions regarding what factors change the classifications
of the data. TARZAN can succinctly present the results from very large
what-if queries. For example, in one of the studies presented, we can
view the significant features from 10<sup>9</sup> what-if queries on
half a page},
author = {Menzies, T. and Sinsel, E.},
booktitle = {Proceedings ASE 2000. Fifteenth IEEE International Conference on Automated Software Engineering},
doi = {10.1109/ASE.2000.873661},
isbn = {0-7695-0710-7},
issn = {1527-1366},
title = {{Practical large scale what-if queries: case studies with software
risk assessment}},
year = {2000}
}


@article{me09b,
  title =	 "On the Relative Value of Cross-Company and
                  Within-Company Data for Defect Prediction",
  author =	 "B. Turhan and Tim Menzies and A. Bener and
                  J. Distefano",
  year =	 2009,
  journal =	 "Empirical Software Engineering",
  volume =	 68,
  number =	 2,
  pages =	 "278-290",
  note =	 "Available from
                  \url{http://menzies.us/pdf/08ccwc.pdf}",
  class =	 "hJ"
}

@misc{Zadeh1965,
abstract = {A fuzzy set is a class of objects with a continuum of grades of membership. Such a set is characterized by a membership (characteristic) function which assigns to each object a grade of membership ranging between zero and one. The notions of inclusion, union, intersection, complement, relation, convexity, etc., are extended to such sets, and various properties of these notions in the context of fuzzy sets are established. In particular, a separation theorem for convex fuzzy sets is proved without requiring that the fuzzy sets be disjoint.},
author = {Zadeh, L.A.},
booktitle = {Information and Control},
doi = {10.1016/S0019-9958(65)90241-X},
isbn = {0019-9958},
issn = {00199958},
number = {3},
pages = {338--353},
title = {{Fuzzy sets}},
volume = {8},
year = {1965}
}


@article{me07b,
  author =	"T. Menzies and J. Greenwald and A. Frank",
  year =	2007,
  month =	"Jan",
  volume={33}, 
  number={1}, 
  pages={2-13}, 
  title =	"Data Mining Static Code Attributes to Learn Defect
                  Predictors",
  journal =	"IEEE Trans. Softw Eng.",
  note =	"Available from
                  \url{http://menzies.us/pdf/06learnPredict.pdf}",
  class =	"hJ", 
}


@article{me11f,
author = {Lumpe, M and Vasa, R and Menzies, T and Rush, R and Turhan, R},
journal = {International Journal of Software Engineering and Knowledge Engineering},
number = {45},
pages = {725--753},
title = {{Learning Better Inspection Optimization Policies}},
volume = {21},
year = {2011}
}


@article{jiang2013incremental,
  title={Incremental Development of Fault Prediction Models},
  author={Jiang, Yue and Cukic, Bojan and Menzies, Tim and Lin, Jie},
  journal={International Journal of Software Engineering and Knowledge Engineering},
  volume={23},
  number={10},
  pages={1399--1425},
  year={2013},
  publisher={World Scientific Publishing Company}
}


@book{fastmap,
  title={FastMap: A fast algorithm for indexing, data-mining and visualization of traditional and multimedia datasets},
  author={Faloutsos, Christos and Lin, King-Ip},
  volume={24},
  number={2},
  year={1995},
  publisher={ACM}
}
@inproceedings{xomo,
  title={Xomo: Understanding development options for autonomy},
  author={Menzies, Tim}
}

@inproceedings{Carver2003,
abstract = {Several empirical studies have been carried out with college students as subjects in the last few years. Researchers often use these studies to pilot experiments before they are carried out in industrial environments. Reports on these studies usually focus on the results obtained and issues such as their external validity. However, the effects and value of empirical studies with students may go beyond the contribution to scientific literature. For instance, the pedagogical challenges and value of these studies is hardly ever stressed. We identify four primary actors that are involved in these empirical studies, i.e., researchers, students, instructors, and industry. We discuss the costs and benefits of empirical studies with students for these actors, which are different because of the actors' different goals, expectations, and constraints, which must be recognized to fully exploit empirical studies with students. We also provide some advice on how to carry out empirical studies with students based on our experiences.},
author = {Carver, Jeffrey and Jaccheri, Letizia and Morasca, Sandro and Shull, Forrest},
booktitle = {Proceedings of the 9th International Software Metrics Symposium (METRICS '03)},
doi = {10.1109/METRIC.2003.1232471},
isbn = {0-7695-1987-3},
pages = {239--249},
title = {{Issues in using students in empirical studies in software engineering education}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1232471},
year = {2003}
}

@book{Schank1977,
abstract = {Related to my topic. However, it's not really clear how it all works together. Moore BF 311 S378},
author = {Schank, Roger C and Abelson, Robert P},
booktitle = {Representation},
file = {::},
isbn = {9780470990339},
pages = {272},
pmid = {91},
title = {{Scripts, Plans, Goals and Understanding}},
url = {http://books.google.it/books?id=YZ99AAAAMAAJ},
volume = {Discourse},
year = {1977}
}


@article{Kolodner1992,
abstract = {Case-based reasoning means using old experiences to understand and solve new problems. In case-based reasoning, a reasoner remembers a previous situation similar to the current one and uses that to solve the new problem. Case- based reasoning can mean adapting old solutions to meet new demands; using old cases to explain new situations; using old cases to critique new solutions; or reasoning from precedents to interpret a new situation (much like lawyers do) or create an equitable solution to a new problem (much like labor mediators do). This paper discusses the processes involved in case-based reasoning and the tasks for which case-based reasoning is useful.},
author = {Kolodner, Janet L.},
doi = {10.1007/BF00155578},
isbn = {978-3-540-60654-3},
issn = {02692821},
journal = {Artificial Intelligence Review},
keywords = {Case-based reasoning,experience,problem-solving},
number = {1},
pages = {3--34},
title = {{An introduction to case-based reasoning}},
volume = {6},
year = {1992}
}

@article{dean1995planning,
  title={Planning under time constraints in stochastic domains},
  author={Dean, Thomas and Kaelbling, Leslie Pack and Kirman, Jak and Nicholson, Ann},
  journal={Artificial Intelligence},
  volume={76},
  number={1-2},
  pages={35--74},
  year={1995},
  publisher={Elsevier}
}
@misc{Bylander1994,
abstract = {I present several computationalcomplexity results for propositionalSTRIPSplanning, i.e., STRIPSplanning restricted to ground formulas. Different planning problems can be defined by restricting the type of formulas, placing limits on the number of pre-and postconditions, by restricting negation in pre- and postconditions, and by requiring optimal plans. For these types of restrictions, I show when planning is tractable (polynomial) and intractable (NP-hard). In general, it is PSPACE-complete to determine if a given planning instance has any solutions. Extremely severe restrictions on both the operators and the formulas are required to guarantee polynomial time or even NP-completeness. For example, when only ground literals are permitted, determining plan existence is PSPACE-complete even if operators are limited to two preconditions and two postconditions. When definite Horn ground formulas are permitted, determining plan existence is PSPACE-complete even if operators are limited to zero preconditions and one postcondition. One of the interesting tractable problems is if each operator is restricted to positive preconditions and one postcondition (only ground literals). The blocks-world problem, slightly modified, is a subproblem of this restricted planning problem. These results in combination with previous analyses are not encouraging for domain-independent planning.},
author = {Bylander, Tom},
booktitle = {Artificial Intelligence},
doi = {10.1016/0004-3702(94)90081-7},
issn = {00043702},
number = {1-2},
pages = {165--204},
title = {{The computational complexity of propositional STRIPS planning}},
volume = {69},
year = {1994}
}


@inproceedings{me09m,
annote = {Available from  http://menzies.us/pdf/09fssga.pdf},
author = {Andrews, Jamie and Menzies, Tim},
booktitle = {PROMISE'09},
title = {{On the Value of Combining Feature Subset Selection with Genetic Algorithms: Faster Learning of Coverage Models}},
year = {2009}
}

@misc{Fikes1971,
abstract = {We describe a new problem solver called STRIPS that attempts to find a sequence of operators in a space of world models to transform a given initial world model in which a given goal formula can be proven to be true. STRIPS represents a world model as an arbitrary collection in first-order predicate calculus formulas and is designed to work with models consisting of large numbers of formula. It employs a resolution theorem prover to answer questions of particular models and uses means-ends analysis to guide it to the desired goal-satisfying model.},
author = {Fikes, Richard E. and Nilsson, Nils J.},
booktitle = {Artificial Intelligence},
doi = {10.1016/0004-3702(71)90010-5},
isbn = {0004-3702},
issn = {00043702},
number = {3-4},
pages = {189--208},
title = {{Strips: A new approach to the application of theorem proving to problem solving}},
volume = {2},
year = {1971}
}

@inproceedings{andrews07,
annote = {Available from  http://menzies.us/pdf/07ase-nighthawk.pdf},
author = {Andrews, J H and Li, F C H and Menzies, T},
booktitle = {IEEE ASE'07},
title = {{Nighthawk: A Two-Level Genetic-Random Unit Test Data Generator}},
year = {2007}
}



@article{andrews10,
author = {Andrews, James H and Menzies, Tim and Li, Felix C H},
journal = {IEEE Transactions on Software Engineering},
month = mar,
title = {{Genetic Algorithms for Randomized Unit Testing}},
year = {2010}
}


@article{Hill1965,
author = {Hill, Austin Bradford},
journal = {Proceedings of the Royal Society of Medicine},
number = {5},
pages = {295--300},
title = {{The Environment and Disease: Association or Causation?}},
volume = {58},
year = {1965}
}

@in proceeeings{Seth2007,
abstract = {Granger causality is a statistical concept of causality that is based on prediction. According to Granger causality, if a signal X1 "Granger-causes" (or "G-causes") a signal X2, then past values of X1 should contain information that helps predict X2 above and beyond the information contained in past values of X2 alone. Its mathematical formulation is based on linear regression modeling of stochastic processes (Granger 1969). More complex extensions to nonlinear cases exist, however these extensions are often more difficult to apply in practice.},
author = {Seth, Anil},
booktitle = {Scholarpedia},
doi = {10.4249/scholarpedia.1667},
issn = {1941-6016},
number = {7},
pages = {1667},
pmid = {20812909},
title = {{Granger causality}},
volume = {2},
year = {2007}
}

@article{granger80,
abstract = {A general definition of causality is introduced and then specialized to become operational. By considering simple examples a number of advantages and also difficulties are discussed.},
author = {{C. W. J. Granger}},
doi = {10.1016/0165-1889(80)90069-X},
isbn = {0165-1889},
issn = {01651889},
journal = {Journal of Economic Dynamics and Control},
pages = {329--352},
title = {{Testing For Causality}},
volume = {2},
year = {1980}
}


@book{Breiman1984,
abstract = {The methodology used to construct tree structured rules is the focus of this monograph. Unlike many other statistical procedures, which moved from pencil and paper to calculators, this text's use of trees was unthinkable before computers. Both the practical and theoretical sides have been developed in the authors' study of tree methods. Classification and Regression Trees reflects these two sides, covering the use of trees as a data analysis method, and in a more mathematical framework, proving some of their fundamental properties.},
author = {Breiman, L and Friedman, J H and Olshen, R A and Stone, C J},
booktitle = {The Wadsworth statisticsprobability series},
isbn = {0412048418},
pages = {368},
pmid = {462029},
title = {{Classification and Regression Trees}},
volume = {19},
year = {1984}
}
@article{Breiman2001,
abstract = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the corre- lation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund \& R. Schapire, Machine Learning: Proceedings of the Thirteenth Interna- tional conference, ∗∗∗, 148–156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression. Keywords:},
archivePrefix = {arXiv},
arxivId = {http://dx.doi.org/10.1023\%2FA\%3A1010933404324},
author = {Breiman, L},
doi = {10.1023/A:1010933404324},
eprint = {/dx.doi.org/10.1023\%2FA\%3A1010933404324},
isbn = {0885-6125},
issn = {0885-6125},
journal = {Machine learning},
keywords = {classification,ensemble,regression},
pages = {5--32},
pmid = {21816105},
primaryClass = {http:},
title = {{Random forests}},
url = {http://link.springer.com/article/10.1023/A:1010933404324},
year = {2001}
}

@article{mittas13,
  author =	{Nikolaos Mittas and Lefteris Angelis},
  title =	{Ranking and Clustering Software Cost Estimation
                  Models through a Multiple Comparisons Algorithm},
  journal =	{IEEE Trans. Software Eng.},
  volume =	39,
  number =	4,
  year =	2013,
  pages =	{537-551},
}
@book{efron93,
  author =	"Efron, Bradley and Tibshirani, Robert J",
  title =	"An introduction to the bootstrap",
  publisher =	"Chapman and Hall",
  address =	"London",
  series =	"Mono. Stat. Appl. Probab.",
  year =	1993,
}


@INPROCEEDINGS{arcuri11,
author={Arcuri, A. and Briand, L.}, 
booktitle={ICSE'11},
title={A practical guide for using statistical tests to assess randomized algorithms in software engineering}, 
year={2011}, 
pages={1-10}}


@ARTICLE{localvsglobal, 
  author={Menzies, T. and Butcher, A. and Cok, D. and Marcus, A. and Layman, L. and Shull, F. and Turhan, B. and Zimmermann, T.}, 
  journal={Software Engineering, IEEE Transactions on}, 
  title={Local versus Global Lessons for Defect Prediction and Effort Estimation}, 
  year={2013}, 
  month={June}, 
  volume={39}, 
  number={6}, 
  pages={822-834}, 
  keywords={automatic test pattern generation;data mining;pattern clustering;PROMISE repository;automated clustering tools;data source;defect dataset;defect prediction;effort estimation;global lessons;learned lesson generated rule;local lessons;Context;Data models;Estimation;Java;Measurement;Software;Telecommunications;Data mining;clustering;defect prediction;effort estimation}, 
  doi={10.1109/TSE.2012.83}, 
  ISSN={0098-5589},}
@ARTICLE{lessmann, 
  author={Lessmann, S. and Baesens, B. and Mues, C. and Pietsch, S.}, 
  journal={Software Engineering, IEEE Transactions on}, 
  title={Benchmarking Classification Models for Software Defect Prediction: A Proposed Framework and Novel Findings}, 
  year={2008}, 
  month={July}, 
  volume={34}, 
  number={4}, 
  pages={485-496}, 
  keywords={benchmark testing;software quality;statistical testing;benchmarking classification models;code attributes;fault-prone modules;metric-based classification;predictive classification models;proprietary data sets;software defect prediction;software quality;statistical testing procedures;testing efficiency;Complexity measures;Data mining;Formal methods;Statistical methods}, 
  doi={10.1109/TSE.2008.35}, 
  ISSN={0098-5589},}
@INPROCEEDINGS{smote2, 
  author={Pelayo, L. and Dick, S.}, 
  booktitle={Fuzzy Information Processing Society, 2007. NAFIPS '07. Annual Meeting of the North American}, 
  title={Applying Novel Resampling Strategies To Software Defect Prediction}, 
  year={2007}, 
  month={June}, 
  pages={69-72}, 
  keywords={learning (artificial intelligence);sampling methods;software metrics;software performance evaluation;software reliability;SMOTE technique;benchmark datasets;defect-prone modules;geometric mean classification accuracy;learning algorithms;machine learning;over-sampling minority-class examples;resampling strategy;software complexity;software defect prediction;software reliability;software sophistication;unbalanced datasets;Computer errors;Costs;Joining processes;Machine learning;Machine learning algorithms;Nearest neighbor searches;Sampling methods;Software algorithms;Software reliability;Testing}, 
  doi={10.1109/NAFIPS.2007.383813},}
@article{smote,
  title={SMOTE: synthetic minority over-sampling technique},
  author={Chawla, Nitesh V and Bowyer, Kevin W and Hall, Lawrence O and Kegelmeyer, W Philip},
  journal={Journal of artificial intelligence research},
  volume={16},
  number={1},
  pages={321--357},
  year={2002}
}
@inproceeedings{fu:ase15,
  title="Analytics Without  Tuning Considered Harmful?",
  author="Wei Fu, Tim Menzies, Xipeng Shen",
  booktitle="Submitted to ASE'15",
  year=2015
  }


@INPROCEEDINGS{pelayo07, 
author={Pelayo, L. and Dick, S.}, 
booktitle={Fuzzy Information Processing Society, 2007. NAFIPS '07. Annual Meeting of the North American}, 
title={Applying Novel Resampling Strategies To Software Defect Prediction}, 
year={2007}, 
month={June}, 
pages={69-72}, 
keywords={learning (artificial intelligence);sampling methods;software metrics;software performance evaluation;software reliability;SMOTE technique;benchmark datasets;defect-prone modules;geometric mean classification accuracy;learning algorithms;machine learning;over-sampling minority-class examples;resampling strategy;software complexity;software defect prediction;software reliability;software sophistication;unbalanced datasets;Computer errors;Costs;Joining processes;Machine learning;Machine learning algorithms;Nearest neighbor searches;Sampling methods;Software algorithms;Software reliability;Testing}, 
doi={10.1109/NAFIPS.2007.383813},}

@article{sk,
  title={Ranking and clustering software cost estimation models through a multiple comparisons algorithm},
  author={Mittas, Nikolaos and Angelis, Lefteris},
  journal={Software Engineering, IEEE Transactions on},
  volume={39},
  number={4},
  pages={537--551},
  year={2013},
  publisher={IEEE}
}
@article{shepperd12a,
  author =	 {Martin J. Shepperd and Steven G. MacDonell},
  title =	 {Evaluating prediction systems in software project
                  estimation},
  journal =	 {Information {\&} Software Technology},
  volume =	 54,
  number =	 8,
  year =	 2012,
  pages =	 {820-827},
}
@article{kampenes07,
  author =	 {Vigdis By Kampenes and Tore Dyb{\aa} and Jo Erskine
                  Hannay and Dag I. K. Sj{\o}berg},
  title =	 {A systematic review of effect size in software
                  engineering experiments},
  journal =	 {Information {\&} Software Technology},
  volume =	 49,
  number =	 {11-12},
  year =	 2007,
  pages =	 {1073-1086},
}
@inproceedings{menzies2005xomo,
  title={Xomo: Understanding development options for autonomy},
  author={Menzies, Tim}
}

@article{Hansen2006,
abstract = {Derived from the concept of self-adaptation in evolution strategies, the CMA (Covariance Matrix Adaptation) adapts the covariance matrix of a multi-variate normal search distribution. The CMA was originally designed to perform well with small populations. In this review, the argument starts out with large population sizes, reflecting recent extensions of the CMA algorithm. Commonalities and differences to continuous Estimation of Distribution Algorithms are analyzed. The aspects of reliability of the estimation, overall step size control, and independence from the coordinate system (invariance) become particularly important in small populations sizes. Consequently, performing the adaptation task with small populations is more intricate.},
author = {Hansen, Nikolaus},
doi = {10.1007/11007937\_4},
isbn = {3540290060},
issn = {14349922},
journal = {Studies in Fuzziness and Soft Computing},
pages = {75--102},
title = {{The CMA evolution strategy: A comparing review}},
volume = {192},
year = {2006}
}

@article{harman12dec,
author = {Harman, Mark and Mansouri, S Afshin and Zhang, Yuanyuan},
issn = {0360-0300},
journal = {ACM Comput. Surv.},
month = dec,
number = {1},
pages = {11:1----11:61},
title = {{Search-based Software Engineering: Trends, Techniques and Applications}},
volume = {45},
year = {2012}
}

@inproceedings{Kocaguneli2013:ep,
abstract = {We offer a case study illustrating three rules for reporting$\backslash$nresearch to industrial practitioners. Firstly, report “relevant”$\backslash$nresults; e.g. this paper explores the effects of distributed development$\backslash$non software products. Second: “recheck” old results if new results call$\backslash$nthem into question. Many papers say distributed development can be$\backslash$nharmful to software quality. Previous work by Bird et al. allayed that$\backslash$nconcern but a recent paper by Posnett et al. suggests that the Bird$\backslash$nresult was biased by the kinds of files it explored. Hence, this paper$\backslash$nrechecks that result and finds significant differences in Microsoft$\backslash$nproducts (Office 2010) between software built by distributed or$\backslash$ncollocated teams. At first glance, this recheck calls into question the$\backslash$nwidespread practice of distributed development. Our third rule is to$\backslash$n“reflect” on results to avoid confusing practitioners with an arcane$\backslash$nmathematical analysis. For example, on reflection, we found that the$\backslash$neffect size of the differences seen in the collocated and distributed$\backslash$nsoftware was so small that it need not concern industrial practitioners.$\backslash$nOur conclusion is that at least for Microsoft products, distributed$\backslash$ndevelopment is not considered harmful.},
author = {Kocaguneli, Ekrem and Zimmermann, Thomas and Bird, Christian and Nagappan, Nachiappan and Menzies, Tim},
booktitle = {Proceedings - International Conference on Software Engineering},
doi = {10.1109/ICSE.2013.6606637},
isbn = {9781467330763},
issn = {02705257},
pages = {882--890},
title = {{Distributed development considered harmful?}},
year = {2013}
}


@inproceedings{romano06,
  title="J. Romano, J. D. Kromrey, J. Coraggio, J. Skowronek",
   title="Appropriate statistics for ordinal level data: Should we really be using t-test and cohen's d for evaluating group differences on the NSSE and other surveys?",
    booktitle="Annual meeting of the Florida Association of Institutional Research",
    year=2006
    }
    

@article{boehm2009software,
  title={Software Cost Estimation with COCOMO II},
  author={Boehm, Barry W and Abts, Chris and Brown, A Winsor and Chulani, Sunita and Clark, Bradford K and Horowitz, Ellis and Madachy, Ray and Reifer, Donald J and Steece, Bert},
  year={2009},
  publisher={Prentice Hall Press}
}

@article{krall14,
author = {Krall, J and Menzies, T},
file = {:Users/timm/svns/doc/optimalML/galeTse.pdf:pdf},
journal = {IEEE Transactions on Software Engineering (to apear)},
title = {{GALE: Geometric Active Learning for Search-based Software Engineering}},
year = {2015}
}



@article{Ludewig2003,
abstract = {Modelling is a concept fundamental for soft- ware engineering. In this paper, the word is defined and discussed fromvarious perspectives. The most important types ofmodels are presented, and examples are given. Models are very useful, but sometimes also dangerous, in particular to those who use them unconsciously. Such problems are shown. Finally, the role of models in soft- ware engineering research is discussed},
author = {Ludewig, Jochen},
doi = {10.1007/s10270-003-0020-3},
file = {:Users/rkrsn/Documents/Mendeley Desktop/Ludewig\_Models in software engineering - an introduction.pdf:pdf},
isbn = {1619-1366},
issn = {1619-1366},
journal = {Software and Systems Modeling},
keywords = {Models –Software engineering –Metaphors –SESAM},
number = {1},
pages = {5--14},
title = {{Models in software engineering - an introduction}},
url = {http://link.springer.com/10.1007/s10270-003-0020-3},
volume = {2},
year = {2003}
}

@article{keung2008analogy,
  title={Analogy-X: providing statistical inference to analogy-based software cost estimation},
  author={Keung, Jacky Wai and Kitchenham, Barbara A and Jeffery, D Ross},
  journal={Software Engineering, IEEE Transactions on},
  volume={34},
  number={4},
  pages={471--484},
  year={2008},
  publisher={IEEE}
}
@article{shepperd1997estimating,
  title={Estimating software project effort using analogies},
  author={Shepperd, Martin and Schofield, Chris},
  journal={Software Engineering, IEEE Transactions on},
  volume={23},
  number={11},
  pages={736--743},
  year={1997},
  publisher={IEEE}
}

@misc{promiserepo,
  author =	 {Menzies, T. and Rees-Jones, M. and Krishna, R. and Pape, C.},
  year =	 {2015},
  title =	 {The Promise Repository of Empirical Software Engineering Data},
  notes =	 {http://openscience.us/repo. North Carolina State University, Department of Computer Science}
}

@article{Harman2009,
abstract = {In the past five years there has been a dramatic increase in work on Search Based Software Engineering (SBSE), an approach to software engineering in which search based optimisation algorithms are used to address problems in Software Engineering. SBSE has been applied to problems throughout the Software Engineering lifecycle, from requirements and project planning to maintenance and re-engineering. The approach is attractive because it offers a suite of adaptive automated and semi-automated solutions in situations typified by large complex problem spaces with multiple competing and conflicting objectives. This paper provides a review and classification of literature on SBSE. The paper identifies research trends and relationships between the techniques applied and the applications to which they have been applied and highlights gaps in the literature and avenues for further research.},
author = {Harman, M and Mansouri, Sa and Zhang, Y},
doi = {10.1016/S0950-5849(01)00189-6},
file = {::},
issn = {09505849},
journal = {Engineering},
number = {TR-09-03},
pages = {1--78},
title = {{Search Based Software Engineering: A Comprehensive Analysis and Review of Trends Techniques and Applications}},
url = {http://discovery.ucl.ac.uk/170689/},
year = {2009}
}


@article{Harman2011,
abstract = {The aim of Search Based Software Engineering (SBSE) research is to move software engineering problems from human-based search to machine-based search, using a variety of techniques from the metaheuristic search, operations research and evolutionary computation paradigms. The idea is to exploit humans creativity and machines tenacity and reliability, rather than requiring humans to perform the more tedious, error prone and thereby costly aspects of the engineering process. SBSE can also provide insights and decision support. This tutorial will present the reader with a step-by-step guide to the application of SBSE techniques to Software Engineering. It assumes neither previous knowledge nor experience with Search Based Optimisation. The intention is that the tutorial will cover sufficient material to allow the reader to become productive in successfully applying search based optimisation to a chosen Software Engineering problem of interest.},
author = {Harman, M and McMinn, P and {De Souza}, JT and Yoo, S},
doi = {10.1007/978-3-642-25231-0\_1},
journal = {Search},
pages = {1--59},
title = {{Search based software engineering: Techniques, taxonomy, tutorial}},
url = {http://discovery.ucl.ac.uk/1340709/},
volume = {2012},
year = {2011}
}


@article{walkerden1999empirical,
  title={An empirical study of analogy-based software effort estimation},
  author={Walkerden, Fiona and Jeffery, Ross},
  journal={Empirical software engineering},
  volume={4},
  number={2},
  pages={135--158},
  year={1999},
  publisher={Springer}
}
@ARTICLE{6600685, 
author={Menzies, T. and Brady, A. and Keung, J. and Hihn, J. and Williams, S. and El-Rawas, O. and Green, P. and Boehm, B.}, 
journal={Software Engineering, IEEE Transactions on}, 
title={Learning Project Management Decisions: A Case Study with Case-Based Reasoning versus Data Farming}, 
year={2013}, 
month={Dec}, 
volume={39}, 
number={12}, 
pages={1698-1713}, 
keywords={Monte Carlo methods;case-based reasoning;data handling;learning (artificial intelligence);project management;sampling methods;software management;CBR;Monte Carlo sampling;SEESAW;case-based reasoning;data farming;project management decision learning;software project data;Data models;Mathematical model;Monte Carlo methods;Project management;Search methods;Software engineering;COCOMO;Search-based software engineering;case-based reasoning;data farming}, 
doi={10.1109/TSE.2013.43}, 
ISSN={0098-5589},}
@inproceedings{kocaguneli2010use,
  title={When to use data from other projects for effort estimation},
  author={Kocaguneli, Ekrem and Gay, Gregory and Menzies, Tim and Yang, Ye and Keung, Jacky W},
  booktitle={Proceedings of the IEEE/ACM international conference on Automated software engineering},
  pages={321--324},
  year={2010},
  organization={ACM}
}
@article{kocaguneli2012exploiting,
  title={Exploiting the essential assumptions of analogy-based effort estimation},
  author={Kocaguneli, Ekrem and Menzies, Tim and Bener, Ayse and Keung, Jacky W},
  journal={Software Engineering, IEEE Transactions on},
  volume={38},
  number={2},
  pages={425--438},
  year={2012},
  publisher={IEEE}
}
@ARTICLE{1438374, 
author={Myrtveit, I. and Stensrud, E. and Shepperd, M.}, 
journal={Software Engineering, IEEE Transactions on}, 
title={Reliability and validity in comparative studies of software prediction models}, 
year={2005}, 
month={May}, 
volume={31}, 
number={5}, 
pages={380-391}, 
keywords={convergence;function approximation;learning (artificial intelligence);program verification;regression analysis;software cost estimation;software metrics;software reliability;accuracy indicator;analogy estimation;arbitrary function approximators;convergence;cost estimation;cross validation;data sample;empirical method;machine learning model;regression model;simulation;software metrics;software prediction model;software reliability;software validity;Analytical models;Artificial neural networks;Convergence;Cost function;Machine learning;Mathematical model;Maximum likelihood estimation;Predictive models;Programming;Regression analysis;Index Terms- Software metrics;accuracy indicators.;arbitrary function approximators;cost estimation;cross-validation;empirical methods;estimation by analogy;machine learning;regression analysis;reliability;simulation;validity}, 
doi={10.1109/TSE.2005.58}, 
ISSN={0098-5589},}
@article{hall03,
  title={Benchmarking attribute selection techniques for discrete class data mining},
  author={Hall, Mark Andrew and Holmes, Geoffrey},
  journal={Knowledge and Data Engineering, IEEE Transactions on},
  volume={15},
  number={6},
  pages={1437--1447},
  year={2003},
  publisher={IEEE}
}

@inproceedings{jureczko10,
author = {Jureczko, Marian and Madeyski, Lech},
booktitle = {Proceedings of the 6th International Conference on Predictive Models in Software Engineering},
pages = {9:1----9:10},
publisher = {ACM},
series = {PROMISE '10},
title = {{Towards identifying software project clusters with regard to defect prediction}},
year = {2010}
}

@inproceedings{sven12,
  title={Predicting performance via automated feature-interaction detection},
  author={Siegmund, Norbert and Kolesnikov, Sergiy S and K{\"a}stner, Christian and Apel, Sven and Batory, Don and Rosenm{\"u}ller, Marko and Saake, Gunter},
  booktitle={Proceedings of the 34th International Conference on Software Engineering},
  pages={167--177},
  year={2012},
  organization={IEEE Press}
}
@inproceedings{vapp,
  title={Variability-aware performance prediction: A statistical learning approach},
  author={Guo, Jianmei and Czarnecki, Krzysztof and Apel, Sven and Siegmund, Norbert and Wasowski, Andrzej},
  booktitle={Automated Software Engineering (ASE), 2013 IEEE/ACM 28th International Conference on},
  pages={301--311},
  year={2013},
  organization={IEEE}
}
@article{Menzies2010,
abstract = {Building quality software is expensive and software quality assurance (QA) budgets are limited. Data miners can learn defect predictors from static code features which can be used to control QA resources; e.g. to focus on the parts of the code predicted to be more defective. Recent results show that better data mining technology is not leading to better defect predictors. We hypothesize that we have reached the limits of the standard learning goal of maximizing area under the curve (AUC) of the probability of false alarms and probability of detection AUC(pd, pf) ; i.e. the area under the curve of a probability of false alarm versus probability of detection. Accordingly, we explore changing the standard goal. Learners that maximize AUC(effort, pd) find the smallest set of modules that contain the most errors. WHICH is a meta-learner framework that can be quickly customized to different goals. When customized to AUC(effort, pd), WHICH out-performs all the data mining methods studied here. More importantly, measured in terms of this new goal, certain widely used learners perform much worse than simple manual methods. Hence, we advise against the indiscriminate use of learners. Learners must be chosen and customized to the goal at hand. With the right architecture (e.g. WHICH), tuning a learner to specific local business goals can be a simple task.},
author = {Menzies, Tim and Milton, Zach and Turhan, Burak and Cukic, Bojan and Jiang, Yue and Bener, Ayşe},
doi = {10.1007/s10515-010-0069-5},
issn = {09288910},
journal = {Automated Software Engineering},
keywords = {Defect prediction,Static code features,Which},
number = {4},
pages = {375--407},
title = {{Defect prediction from static code features: Current results, limitations, new approaches}},
volume = {17},
year = {2010}
}



@article{Irani1993,
abstract = {Since most real-world applications of classification learning involve continuous-valued attributes, properly addressing the discretization process is an important problem. This paper addresses the use of the entropy minimization heuristic for discrctizing the range of a continuous-valued attribute into multiple intervals. We briefly present theoretical evidence for the apropiateness of this heuristic for use in the binary discretization algorithm used in ID3, C4, CART, and other learning algorithms. The results serve to justify extending the algorithm to derive multiple intervals. We formally derive a criterion based on the minimum description length principle for deciding the partition of intervals. We demonstrate via empirical evaluation on several real-world data sets that better decision trees are obtained using the new multi-interval algorithm.},
author = {Irani, KB and Fayyad, UM},
file = {::},
isbn = {1-55860-300-X},
issn = {15730565},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
pages = {1022--1027},
title = {{Multi-lnterval Discretization of Continuous-Valued Attributes for Classification learning}},
year = {1993}
}


@article{Anda2009,
abstract = {The scientific study of a phenomenon requires it to be reproducible. Mature engineering industries are recognized by projects and products that are, to some extent, reproducible. Yet, reproducibility in software engineering (SE) has not been investigated thoroughly, despite the fact that lack of reproducibility has both practical and scientific consequences. We report a longitudinal multiple-case study of variations and reproducibility in software development, from bidding to deployment, on the basis of the same requirement specification. In a call for tender to 81 companies, 35 responded. Four of them developed the system independently. The firm price, planned schedule, and planned development process, had, respectively, ldquolow,rdquo ldquolow,rdquo and ldquomediumrdquo reproducibilities. The contractor's costs, actual lead time, and schedule overrun of the projects had, respectively, ldquomedium,rdquo ldquohigh,rdquo and ldquolowrdquo reproducibilities. The quality dimensions of the delivered products, reliability, usability, and maintainability had, respectively, ldquolow,rdquo "high,rdquo and ldquolowrdquo reproducibilities. Moreover, variability for predictable reasons is also included in the notion of reproducibility. We found that the observed outcome of the four development projects matched our expectations, which were formulated partially on the basis of SE folklore. Nevertheless, achieving more reproducibility in SE remains a great challenge for SE research, education, and industry.},
author = {Anda, Bente C D and Sj\o berg, Dag I K and Mockus, Audris},
doi = {10.1109/TSE.2008.89},
isbn = {0098-5589},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Multiple-case study,Software engineering life cycle,Software process,Software project success,Software quality},
number = {3},
pages = {407--429},
title = {{Variability and reproducibility in software engineering: A study of four companies that developed the same system}},
volume = {35},
year = {2009}
}


@article{menzies2013,
abstract = {Existing research is unclear on how to generate lessons learned for defect prediction and effort estimation. Should we seek lessons that are global to multiple projects or just local to particular projects? This paper aims to comparatively evaluate local versus global lessons learned for effort estimation and defect prediction. We applied automated clustering tools to effort and defect datasets from the PROMISE repository. Rule learners generated lessons learned from all the data, from local projects, or just from each cluster. The results indicate that the lessons learned after combining small parts of different data sources (i.e., the clusters) were superior to either generalizations formed over all the data or local lessons formed from particular projects. We conclude that when researchers attempt to draw lessons from some historical data source, they should 1) ignore any existing local divisions into multiple sources, 2) cluster across all available data, then 3) restrict the learning of lessons to the clusters from other sources that are nearest to the test data.},
author = {Menzies, Tim and Butcher, Andrew and Cok, David and Marcus, Andrian and Layman, Lucas and Shull, Forrest and Turhan, Burak and Zimmermann, Thomas},
doi = {10.1109/TSE.2012.83},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Data mining,clustering,defect prediction,effort estimation},
number = {6},
pages = {822--834},
title = {{Local versus global lessons for defect prediction and effort estimation}},
volume = {39},
year = {2013}
}


@misc{promise,
  authors =	 "Menzies, T., Rees-Jones, M.,
                  Krishna, R., Pape, C.",
  year =	 2015,
  title =	 "The {P}romise {R}epository of
                  {E}mpirical {S}oftware {E}ngineering
                  {D}ata",
  note =	 "http://openscience.us/repo.  North
                  Carolina State University,
                  Department of Computer Science"
}

@mastersthesis{div14,
  title="Exploring Essential content of Defect Prediction 
         and Effort Estimation through Data Reduction",
  year=2014,
  author="Divya Ganesan",
  school="Computer Science, West Virginia University"
 }
 
 

@inproceedings{me12c,
annote = {Available from http://menzies.us/pdf/12idea.pdf},
author = {Borges, R and Menzies, T},
booktitle = {Proceedings of PROMISE'12, Lund, Sweden},
title = {{Learning to Change Projects}},
year = {2012}
}
 
@mastersthesis{nva14,
  title="Cross Trees: Visualizing Estimations using Decision Trees",
  year=2014,
  author="Naveen  Lekkalapudi",
  school="Computer Science, West Virginia University"
 }

@book{fastmap,
  title={FastMap: A fast algorithm for indexing, data-mining and visualization of traditional and multimedia datasets},
  author={Faloutsos, Christos and Lin, King-Ip},
  volume={24},
  number={2},
  year={1995},
  publisher={ACM}
}
@ARTICLE{6600685, 
author={Menzies, T. and Brady, A. and Keung, J. and Hihn, J. and Williams, S. and El-Rawas, O. and Green, P. and Boehm, B.}, 
journal={Software Engineering, IEEE Transactions on}, 
title={Learning Project Management Decisions: A Case Study with Case-Based Reasoning versus Data Farming}, 
year={2013}, 
month={Dec}, 
volume={39}, 
number={12}, 
pages={1698-1713}, 
keywords={Monte Carlo methods;case-based reasoning;data handling;learning (artificial intelligence);project management;sampling methods;software management;CBR;Monte Carlo sampling;SEESAW;case-based reasoning;data farming;project management decision learning;software project data;Data models;Mathematical model;Monte Carlo methods;Project management;Search methods;Software engineering;COCOMO;Search-based software engineering;case-based reasoning;data farming}, 
doi={10.1109/TSE.2013.43}, 
ISSN={0098-5589},}
@inproceedings{kocaguneli2010use,
  title={When to use data from other projects for effort estimation},
  author={Kocaguneli, Ekrem and Gay, Gregory and Menzies, Tim and Yang, Ye and Keung, Jacky W},
  booktitle={Proceedings of the IEEE/ACM international conference on Automated software engineering},
  pages={321--324},
  year={2010},
  organization={ACM}
}

@inproceedings{jureczko10,
author = {Jureczko, Marian and Madeyski, Lech},
booktitle = {Proceedings of the 6th International Conference on Predictive Models in Software Engineering},
pages = {9:1----9:10},
publisher = {ACM},
series = {PROMISE '10},
title = {{Towards identifying software project clusters with regard to defect prediction}},
year = {2010}
}
@article{mittas13,
  author =	{Nikolaos Mittas and Lefteris Angelis},
  title =	{Ranking and Clustering Software Cost Estimation
                  Models through a Multiple Comparisons Algorithm},
  journal =	{IEEE Trans. Software Eng.},
  volume =	39,
  number =	4,
  year =	2013,
  pages =	{537-551},
}
@book{efron93,
  author =	"Efron, Bradley and Tibshirani, Robert J",
  title =	"An introduction to the bootstrap",
  publisher =	"Chapman and Hall",
  address =	"London",
  series =	"Mono. Stat. Appl. Probab.",
  year =	1993,
}

@article{howase,
author = {Krishna, Rahul and Menzies, Tim and Shen, Xipeng and Marcus, Andrian},
title = {{Learning Actionable Analytics (with applications for reducing defects and reducing runtimes)}},
journal = {Submitted to ASE '15, Lincoln, Nebraska},
year = {2015}
}