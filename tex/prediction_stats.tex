\begin{figure*}[bp]
	\small
	\begin{center}
		\begin{minipage}{.46\linewidth}
			\begin{tabular}{r@{~}|l@{~}|r@{~}|l@{~}|r@{~}|r@{~}|} \cline{2-6}
				& \multicolumn{5}{c|}{ }\\ 
				
				& \multicolumn{5}{c|}{ Data set  properties}\\ 
				& \multicolumn{5}{c|}{  }\\ 
				& \multicolumn{2}{c|}{training}   & \multicolumn{3}{c|}{testing}      \\ \cline{2-6}
				data set      & versions           & cases & versions     & cases    & \% defective             \\ \hline
				jedit    & 3.2, 4.0, 4.1, 4.2 & 1257      & 4.3          & 492          & 2 \\
				ivy      & 1.1, 1.4           & 352       & 2.0          & 352          & 11 \\
				camel    & 1.0, 1.2, 1.4      & 1819      & 1.6          & 965          & 19 \\
				ant      & 1.3, 1.4, 1.5, 1.6 & 947       & 1.7          & 745          & 22 \\
				synapse  & 1.0, 1.1           & 379       & 1.2          & 256          & 34 \\
				velocity & 1.4, 1.5           & 410       & 1.6          & 229          & 34 \\
				lucene   & 2.0, 2.2           & 442       & 2.4          & 340          & 59 \\
				poi      & 1.5, 2, 2.5        & 936       & 3.0          & 442          & 64 \\
				\rowcolor{lavenderpink}xerces   & 1.0, 1.2, 1.3      & 1055      & 1.4          & 588          & 74  \\ 
				\rowcolor{lavenderpink}log4j    & 1.0, 1.1           & 244       & 1.2          & 205          & 92   \\
				\rowcolor{lavenderpink}xalan    & 2.4, 2.5, 2.6      & 2411      & 2.7          & 909          & 99  \\\hline 
				
				
			\end{tabular}\end{minipage}\begin{minipage}{.4\linewidth}
			\begin{tabular}{|rrr|rrr|rr|l} \cline{1-8}
				\multicolumn{8}{|c|}{  }\\
				\multicolumn{8}{|c|}{  Results from learning}\\
				\multicolumn{8}{|c|}{   }\\
				\multicolumn{3}{|c|}{untuned} & \multicolumn{3}{c|}{tuned} & \multicolumn{2}{c|}{change}\\
				\cline{1-8}
				
				pd & pf & good? & pd & pf & good? & pd & pf\\\cline{1-8}
				55 & 29 &   & 64 & 29 & y & 9 & 0&$\star$\\
				65 & 35 & y & 65 & 28 & y & 0 & -7&$\star$\\
				49 & 31 &   & 56 & 37 &   & 5 & 6\\
				49 & 13 & y & 63 & 16 & y & 14 & 3&$\star$\\
				45 & 19 &   & 47 & 15 &   & 2 & -4\\
				78 & 60 &   & 76 & 60 &   & -2 & 0\\
				56 & 25 &   & 60 & 25 & y & 4 & 0\\
				56 & 31 &   & 60 & 10 & y & 4 & -21&$\star$\\
			\rowcolor{lavenderpink}	30 & 31 &   & 40 & 29 &   & 10 & -2&$\times$\\
				\rowcolor{lavenderpink}32 & 6 &   & 30 & 6 &   & -2 & 0&$\times$\\
				\rowcolor{lavenderpink}38 & 9 &   & 47 & 9 &   & 9 & 0&$\times$\\
				\hline 
			\end{tabular}
			
		\end{minipage}
	\end{center}    
	
	\caption{Training and test {\em data set properties} for the Jureczko data sets,
		sorted in ascending order of \% defective examples.
		On the right-hand-side, we show the {\em results from learning}.
		Data is ``good'' if it has recall over 60\% and false alarm under 40\%
		(and note that, after tuning, there are more ``good'' than before).
		Data   marked with ``$\star$'' show large improvements in performance, after tuning.
		The data in  the  \colorbox{lavenderpink}{highlighted} rows, marked with ``$\times$'', are ``not good'' since their test suites  have so few non-defective examples (less than 5\% of the total sample) that it becomes harder to find better data towards which we can displace test data.
	}\label{fig:j}
\end{figure*}
